{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_run"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain-groq\n",
    "%pip install langchain pinecone-client python-dotenv streamlit\n",
    "%pip install -U langchain-community\n",
    "%pip install sentence-transformers\n",
    "%pip install pinecone-client\n",
    "%pip install pinecone-client[grpc]\n",
    "%pip install --upgrade langchain-pinecone\n",
    "%pip install pymupdf pdfplumber\n",
    "%pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "%pip install beautifulsoup4\n",
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description: Legal Document Analysis and Summarization Tool using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# Groq is used as the LLM\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def separate_numbers_and_text(text):\n",
    "    separated_text = re.sub(r\"(\\d+)([a-zA-Z]+)|([a-zA-Z]+)(\\d+)\", r\"\\1 \\2 \\3 \\4\", text)\n",
    "    return separated_text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").text\n",
    "    text = text.lower()\n",
    "\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = \" \".join(word for word in text.split() if word not in stop_words)\n",
    "    text = separate_numbers_and_text(text)\n",
    "    text = \" \".join(text.split())\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # removing extra white space\n",
    "    text = contractions.fix(\n",
    "        text\n",
    "    )  # fixing contractions (ex: can't gets converted to cannot)\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+|https\\S+\", \"<URL>\", text)  # removing URLs\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"<EMAIL>\", text)  # removing email IDs\n",
    "    text = re.sub(\n",
    "        r\"\\b(not)\\s+(\\w+)\\b\", r\"\\1_\\2\", text\n",
    "    )  # handling negations (ex: \"not good\" becomes \"not_good\")\n",
    "\n",
    "    text = \" \".join(stemmer.stem(word) for word in text.split())  # stemming\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_and_preprocess_data(folder_path):\n",
    "    judgement_path = os.path.join(folder_path, \"judgement\")\n",
    "    summary_path = os.path.join(folder_path, \"summary\")\n",
    "\n",
    "    judgement_files = sorted(os.listdir(judgement_path))\n",
    "    summary_files = sorted(os.listdir(summary_path))\n",
    "\n",
    "    judgements = []\n",
    "    summaries = []\n",
    "\n",
    "    for judgement_file, summary_file in zip(judgement_files, summary_files):\n",
    "        with open(\n",
    "            os.path.join(judgement_path, judgement_file), \"r\", encoding=\"utf-8\"\n",
    "        ) as jf:\n",
    "            judgement_text = jf.read()\n",
    "\n",
    "            judgement_text = preprocess_text(judgement_text)\n",
    "            judgements.append(judgement_text)\n",
    "\n",
    "        with open(\n",
    "            os.path.join(summary_path, summary_file), \"r\", encoding=\"utf-8\"\n",
    "        ) as sf:\n",
    "            summary_text = sf.read()\n",
    "\n",
    "            summary_text = preprocess_text(summary_text)\n",
    "            summaries.append(summary_text)\n",
    "\n",
    "    data = pd.DataFrame({\"Judgement\": judgements, \"Summary\": summaries})\n",
    "    return data\n",
    "\n",
    "\n",
    "# Paths to train and test folders\n",
    "train_folder_path = r\"D:\\Rohan\\ML\\Datasets\\legal_dataset\\IN-Abs\\train-data-small\"\n",
    "test_folder_path = r\"D:\\Rohan\\ML\\Datasets\\legal_dataset\\IN-Abs\\test-data\"\n",
    "\n",
    "# Reading and preprocessing train and test data\n",
    "train_data = read_and_preprocess_data(train_folder_path)\n",
    "test_data = read_and_preprocess_data(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appeal lxvi 1949 appeal high court judicatur bombay refer section 66 indian incom tax act 1022 km munshi n p nathvani appel lant mc setalvad attorney gener india h j umrigar respond 1950 may 26 judgment court deliv mehr chand mahajan j appeal judgment high court judicatur bombay incom tax matter rais question whether munici pal properti tax urban immov properti tax payabl relev bombay act allow deduct section 9 1 iv indian incom tax act assesse compani invest compani deriv incom properti citi bombay assess year 1940 41 net incom assesse head properti comput incom tax offic sum rs 621764 deduct gross rent certain payment compani paid relev year rs 122675 municip properti tax rs 32760 urban properti tax deduct two sum claim provis section 9 act first item deduct sum rs 48572 allow ground item repres tenant burden paid assesse otherwis claim disal low appeal assesse appel sistant commission incom tax appel tribu nal unsuccess tribun howev agre refer two question law high court judicatur bombay name 1 whether municip tax paid applic compani allow deduct 555 provis section 9 1 iv indian incom tax act 2 whether urban immov properti tax paid applic compani allow deduct section 9 1 iv section 9 1 v indian incom tax act supplementari refer made cover third question rais us fore necessari refer high court answer three question neg henc appeal question determin whether munic ipal properti tax urban immov properti tax deduct allow claus iv sub section 1 section 9 act decis point depend firstli construct languag employ sub claus iv sub section 1 section 9 act secondli find true natur charact liabil owner relev bombay act payment tax section 9 along relev claus run thu 1 tax shall payabl assesse head incom properti respect bona fide annual valu properti consist build land appurten thereto owner subject follow allow name iv properti subject mortgag capit charg amount interest mortgag charg properti subject annual charg capit charg amount charg properti subject ground rent amount ground rent properti acquir construct repair renew recon struct borrow capit amount interest payabl capit seen claus iv consist four sub claus correspond four deduct allow 556 claus amend act 1939 claus iv contain first third fourth sub claus first sub claus interest deduct whether amount borrow secur properti spent properti question capit expenditur properti express capit charg sub claus cannot connot charg capit properti assess would redund open word clearli indic charg properti therefor opinion capit charg could mean charg creat capit sum ie charg secur discharg liabil capit natur 1933 privi council decid case bijoy singh dudhuria vs commission incom tax calcutta 1 assess section 9 assess ment gener incom assesse liabl pay mainten step mother charg asset decre court li abil voluntarili incur one cast law privi council held amount paid discharg liabil form part real incom includ assess though decis proceed principl outgo part assesse incom framer amend act 1939 want appar extend principl far assess properti concern even case obligatori payment made assesse incom properti charg payment second sub claus name properti subject annual charg capit charg amount charg ad sub claus appel invok support claim deduct municip urban properti tax present case view open word newli ad sub claus express capit charg also use therein cannot refer charg properti think must 1 ilr 60 cal 557 understood sens sub claus 1 say first sub claus provid deduc tion interest capit sum charg properti sub claus provid deduct annual sum charg sum capit sum limit word intend exclud case capit rais secur properti made repay instal commission incom tax bombay vs mahomedbhoy rowji 1 bench bombay high court consid mean word regard annual charg beau mont cj observ follow word think would cover charg secur annual liabil kania j said follow see charg annual unless mean charg respect payment made annual construct word follow judgment appeal gappum kanhaiya lal vs commission incom tax 2 connect appeal us bench allahabad high court agre construct place word bombay case ie word annual charg mean charg secur annual liabil therefor clear conflict judici deci sion mean phrase annual charg occur ring section 3 1 iv mean given natur mean word phrase capit charg beaumont cj case refer took view word mean charg capit kania j howev took differ view observ prepar accept sugg tion document provid certain payment made monthli annual charg immov properti estat individu becom capit charg allahabad judgment appeal 1 ilr 2 ilr 1944 558 word consid mean charg capit said annual charg mean charg secur discharg annual liabil capit charg mean charg secur discharg liabil capit natur think construct natu ral construct section right determin point whether tax disput fall within ambit phrase annual charg capit charg depend provis statut levi section 143 citi bombay municip act 1888 authoris levi gener tax build land citi primari respons pay properti tax lessor vide section 146 act order assess tax provis made determin annual rateabl valu build section 154 section 156 provid mainten assess book entri made everi offici year build citi rateabl valu name person primarili liabl payment properti tax build amount build assess section 167 lay assess ment book need prepar everi offici year public notic shall given accord section 160 162 everi year provis said sec tion section 163 167 shall applic year section lay procedur hear object complaint entri assess book provis clear liabil iti tax determin begin offici year tax annual one recur year year section 143 to 168 concern imposit liabil assess tax year amount tax year liabil payment determin act pre scribe collect chapter collect tax section 197 provid properti tax shall payabl 559 advanc half yearli instal first day april first day octob provis half yearli instal necessarili connot annual li abil word mean annual liabil discharg half yearli payment procedur also prescrib recoveri instal present bill notic demand distress sale final section 212 provid follow properti tax due act respect build land shall subject prior payment land revenu due provinci govern thereupon first charg upon said build ing land creat statutori charg build urban immov abl properti tax leviabl section 22 part vi bombay financ act 1932 on annual let valu properti duti collect tax laid municip manner case municip properti tax section 24 2 b term similar section 212 bombay municip act make land build secur payment tax also purpos section 9 indian incom tax act tax name munici pal properti tax well urban immov properti tax charact stand foot ing mr munshi learn counsel appel con tend tax assess annual valu land build annual tax although may collect interv six month sake conveni incom tax assess annual basi allow deduct payment made liabil incur previ ou year assess allow tax question fell clearli within languag section 9 1 iv learn attorney gener hand argu although tax assess year liabil pay aris begin 560 half year unless notic demand issu bill present liabil pay till charg section 212 act could possibl aris liabil pay half yearli advanc charg annual charg also suggest tax capit charg sens properti secur payment satisfi content rais learn attorney gener sound appar whole tenor two bombay act tax natur annual levi properti assess annual valu properti year annual liabil discharg half yearli instal liabil annual one properti subject provis claus iv sub sec tion 1 section 9 immedi attract great emphasi laid worddu use section 212 municip act said tax becom due act unless time payment arriv charg come exist till charg annual charg think correct construct section 212 word properti tax due act mean properti tax person liabl act tax payabl year made charg properti liabil charg co exist co exten sive provis act afford facil discharg liabil way affect true natur charact annual liabil discharg manner laid section 197 said properti cannot sold recoveri whole amount due year answer queri affirm ie proper ty liabl sale commission incom tax bombay vs mahomedbhoy rowji 1 beaumont cj reject claim deduct tax place relianc 1 ilr 561 section 9 1 v allow deduct respect sum paid account land revenu observ land revenu stand foot municip tax legislatur made special provis deduct sum payabl regard land revenu respect sum paid account municip tax circumst indic deduct allow purpos refer also made provi sion section 10 deal busi allow wherein deduct sum paid account land reve nue local rate municip tax allow conclud part judgment learn chief ju tice said necessari consid exact mean word suffi cient say cover municip tax made charg properti section 212 bombay municip act without determin exact mean word use statut seem us possibl arriv conclus tax within ambit claus elementari primari duti court give effect intent legislatur express word use outsid consider call aid find intent refer claus v section help land revenu charg paramount natur build land deduct respect amount mention express term municip tax hand stand foot land revenu law vari provinc provinc may necessarili charg properti case legi latur seem thought far municip tax properti concern fall within ambit claus iv deduct claimabl respect otherwis deduct allow section 10 head incom busi proceed differ foot construct section 9 aid section 10 apt mislead 562 kania j case arriv conclus influenc consider tax variabl charact ie liabl increas duce variou provis municip act charg natur conting charg great respect may point charg way may variabl conting na ture default made charg ever enforc whenev charg increas reduc year either payment addit borrow moss empir ltd vs inland revenu commission 1 held hous lord fact certain payment conting variabl amount affect charact annual payment word annual must taken qualiti recurr capabl recurr cunard truste vs inland revenu commission 2 held payment capabl recur rent therefor annual payment within mean schedul case iii rule 1 1 even though necessarili recurr year year fact vari amount immateri learn attorney gener view decis support view express kania j relianc place decis high court madra mamad keyi vs commission incom tax madra 3 money paid urban immov properti tax bombay financ act disallow inadmi sibl section 9 1 iv 9 1 v indian incom tax act decis mere follow view express commission incom tax bombay vs mahomedb hoy rowji 4 and arriv independ fresh reason much assist deci sion case allahabad high court 1 2 1948 1 aer 150 3 ilr 4 ilr 563 gappum kanhaiya lal vs commission incometax 1 connect appeal took correct view matter reason given therein approv result appeal allow two question refer high court incom tax tribun cite answer affirm appel cost appeal appeal allow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Judgement\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judgement</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal lxvi 1949 appeal high court judicatur b...</td>\n",
       "      <td>charg creat respect municip properti tax secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>civil appeal no 94 1949 107 834 appeal judgmen...</td>\n",
       "      <td>agreement leas leas indian declar includ must ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imin appeal 40 1951 127 appeal judgment order ...</td>\n",
       "      <td>question whether magistr person interest eas w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>appeal 388 1960 appeal special leav judgment o...</td>\n",
       "      <td>appel member joint hindu famili carri busi gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>appeal 198 1954 appeal judgment order date oct...</td>\n",
       "      <td>appel ruler state baster later integr state ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Judgement  \\\n",
       "0  appeal lxvi 1949 appeal high court judicatur b...   \n",
       "1  civil appeal no 94 1949 107 834 appeal judgmen...   \n",
       "2  imin appeal 40 1951 127 appeal judgment order ...   \n",
       "3  appeal 388 1960 appeal special leav judgment o...   \n",
       "4  appeal 198 1954 appeal judgment order date oct...   \n",
       "\n",
       "                                             Summary  \n",
       "0  charg creat respect municip properti tax secti...  \n",
       "1  agreement leas leas indian declar includ must ...  \n",
       "2  question whether magistr person interest eas w...  \n",
       "3  appel member joint hindu famili carri busi gov...  \n",
       "4  appel ruler state baster later integr state ma...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judgement</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal 101 1959 appeal special leav judgment o...</td>\n",
       "      <td>appel displac person west pakistan grant quasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appeal 52 1957 appeal judgment decre date apri...</td>\n",
       "      <td>appel respond owner adjoin collieri suit prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appeal no 45 46 1959 appeal special leav judgm...</td>\n",
       "      <td>respond firm claim exempt sale tax articl 286 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ion crimin appeal 89 1961 appeal special leav ...</td>\n",
       "      <td>appel tri murder fact establish quarrel appel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>civil appeal 50 1961 appeal special leav award...</td>\n",
       "      <td>employ appel cross cutter saw mill ask show be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Judgement  \\\n",
       "0  appeal 101 1959 appeal special leav judgment o...   \n",
       "1  appeal 52 1957 appeal judgment decre date apri...   \n",
       "2  appeal no 45 46 1959 appeal special leav judgm...   \n",
       "3  ion crimin appeal 89 1961 appeal special leav ...   \n",
       "4  civil appeal 50 1961 appeal special leav award...   \n",
       "\n",
       "                                             Summary  \n",
       "0  appel displac person west pakistan grant quasi...  \n",
       "1  appel respond owner adjoin collieri suit prese...  \n",
       "2  respond firm claim exempt sale tax articl 286 ...  \n",
       "3  appel tri murder fact establish quarrel appel ...  \n",
       "4  employ appel cross cutter saw mill ask show be...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization using TfIdf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(train_data[\"Judgement\"])\n",
    "test_tfidf = tfidf_vectorizer.transform(test_data[\"Judgement\"])\n",
    "\n",
    "train_tfidf_dense = torch.tensor(train_tfidf.toarray(), dtype=torch.float32)\n",
    "test_tfidf_dense = torch.tensor(test_tfidf.toarray(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f015722a7ab4c07917ae11522c0f704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\ProgramFiles\\Huggingface cache\\models--facebook--bart-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fec599543b44d0aa00976bfbe99db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ce5bb9d43b46fb9e6ce18e97df4d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d24a9ebb8645e28ed1309ad1387875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b43aa612ec48168d6727c0ab0087db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7558e0b76f3a4d7881dcd5e3551e957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# downloading the RAG model and initialising\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [\n",
    "    tokenizer(\n",
    "        summary, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    ).input_ids.squeeze(0)\n",
    "    for summary in train_data[\"Summary\"]\n",
    "]\n",
    "test_labels = [\n",
    "    tokenizer(\n",
    "        summary, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    ).input_ids.squeeze(0)\n",
    "    for summary in test_data[\"Summary\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TfidfDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "\n",
    "    # Pad inputs and labels to the same length\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return inputs_padded, labels_padded\n",
    "\n",
    "\n",
    "# Prepare Datasets\n",
    "train_dataset = TfidfDataset(train_tfidf_dense, train_labels)\n",
    "test_dataset = TfidfDataset(test_tfidf_dense, test_labels)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minputs, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1640\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1636\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1637\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1638\u001b[0m         )\n\u001b[1;32m-> 1640\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1641\u001b[0m     input_ids,\n\u001b[0;32m   1642\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1643\u001b[0m     decoder_input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m   1644\u001b[0m     encoder_outputs\u001b[38;5;241m=\u001b[39mencoder_outputs,\n\u001b[0;32m   1645\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m   1646\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1647\u001b[0m     decoder_head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[0;32m   1648\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[0;32m   1649\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1650\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1651\u001b[0m     decoder_inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m   1652\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1653\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1654\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1655\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1656\u001b[0m )\n\u001b[0;32m   1658\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1659\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1508\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1505\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1508\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1509\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1510\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1511\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1512\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1513\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1514\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1515\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1516\u001b[0m     )\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1064\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1061\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1062\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1064\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n\u001b[0;32m   1065\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm_embedding(hidden_states)\n\u001b[0;32m   1066\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):  # Adjust number of epochs as needed\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device).long()\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        outputs = model(input_ids=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
